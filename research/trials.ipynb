{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T20:07:27.220820Z",
     "start_time": "2025-05-26T20:07:27.208855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from platform import system\n",
    "\n",
    "from Demos.OpenEncryptedFileRaw import dst_dir\n",
    "\n",
    "print(\"OK\")"
   ],
   "id": "d9b2fb2353f5f117",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d364ededbeda2f74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:36:48.247835Z",
     "start_time": "2025-05-27T15:36:48.240726Z"
    }
   },
   "cell_type": "code",
   "source": "%pwd",
   "id": "ca0cf1fa018bcdce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Python_AI\\\\MediAI'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:03:53.336461Z",
     "start_time": "2025-05-28T19:03:53.332661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ],
   "id": "4191ac95e3cd6a9c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:03:58.780664Z",
     "start_time": "2025-05-28T19:03:58.775713Z"
    }
   },
   "cell_type": "code",
   "source": "%pwd",
   "id": "70deddaa952115bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Python_AI\\\\MediAI'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:04:01.066118Z",
     "start_time": "2025-05-28T19:04:00.402080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ],
   "id": "e758406558978272",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:04:06.139511Z",
     "start_time": "2025-05-28T19:04:06.136158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Extract Data From PDF\n",
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()  # Fix the variable name here\n",
    "    return documents"
   ],
   "id": "4df68bb3164bbe0c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:05:51.302680Z",
     "start_time": "2025-05-28T19:04:08.597587Z"
    }
   },
   "cell_type": "code",
   "source": "extracted_data=load_pdf_file(data='Data/')",
   "id": "42e0d82e201ff8c8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:10:12.539347Z",
     "start_time": "2025-05-27T18:10:12.535308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Cracted_Chunks\n",
    "def text_split(extracted_data):\n",
    "      text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "      text_chunks=text_splitter.split_documents(extracted_data)\n",
    "      return text_chunks"
   ],
   "id": "70111eb55c2fa8f7",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:05:51.856118Z",
     "start_time": "2025-05-28T19:05:51.335024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of the Chunks\",len(text_chunks))"
   ],
   "id": "9d3297cec3c971db",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m text_chunks=text_split(extracted_data)\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mLength of the Chunks\u001B[39m\u001B[33m\"\u001B[39m,\u001B[38;5;28mlen\u001B[39m(text_chunks))\n",
      "\u001B[31mNameError\u001B[39m: name 'text_split' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:06:53.095389Z",
     "start_time": "2025-05-28T19:06:53.044243Z"
    }
   },
   "cell_type": "code",
   "source": "from langchain.embeddings import HuggingFaceEmbeddings",
   "id": "ba24c8b23195ce3f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:06:12.513836Z",
     "start_time": "2025-05-28T19:06:12.510513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Downloading the Embeddings\n",
    "def download_hugging_face_embeddings():\n",
    "        embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "        return embeddings"
   ],
   "id": "9d27efdaab193368",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:07:07.396231Z",
     "start_time": "2025-05-28T19:06:55.442279Z"
    }
   },
   "cell_type": "code",
   "source": "embeddings=download_hugging_face_embeddings()",
   "id": "dda87c4d8faa556f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nidhi\\AppData\\Local\\Temp\\ipykernel_20676\\3311451588.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "C:\\Users\\nidhi\\.conda\\envs\\MediAI\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:41:16.499468Z",
     "start_time": "2025-05-27T15:41:16.434388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#query_result= embeddings.embed_query(\"Hi I am Nidhin\")\n",
    "#print(\"Length\",len(query_result))"
   ],
   "id": "182e870f4cdd0480",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:12:07.595101Z",
     "start_time": "2025-05-27T18:12:07.588229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "b5b10c6c51e5ff8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:12:10.838167Z",
     "start_time": "2025-05-27T18:12:10.834033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PINECONE_AIP_KEY = os.environ.get('PINECONE_AIP_KEY')\n",
    "OPEN_AI_API_KEY = os.environ.get('OPEN_AI_API_KEY')"
   ],
   "id": "af3ba2df480c3e33",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:12:33.087201Z",
     "start_time": "2025-05-27T18:12:29.866159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_AIP_KEY)\n",
    "\n",
    "index_name = \"medibot\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    )\n",
    ")\n"
   ],
   "id": "76c00beee393e546",
   "outputs": [
    {
     "ename": "PineconeApiException",
     "evalue": "(409)\nReason: Conflict\nHTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'x-pinecone-api-version': '2025-01', 'x-cloud-trace-context': '0d1cf92abf7a99e3c5fdf467020d0e4b', 'date': 'Tue, 27 May 2025 18:12:32 GMT', 'server': 'Google Frontend', 'Content-Length': '85', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"error\":{\"code\":\"ALREADY_EXISTS\",\"message\":\"Resource  already exists\"},\"status\":409}\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mPineconeApiException\u001B[39m                      Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      5\u001B[39m pc = Pinecone(api_key=PINECONE_AIP_KEY)\n\u001B[32m      7\u001B[39m index_name = \u001B[33m\"\u001B[39m\u001B[33mmedibot\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m pc.create_index(\n\u001B[32m     10\u001B[39m     name=index_name,\n\u001B[32m     11\u001B[39m     dimension=\u001B[32m384\u001B[39m,\n\u001B[32m     12\u001B[39m     metric=\u001B[33m\"\u001B[39m\u001B[33mcosine\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     13\u001B[39m     spec=ServerlessSpec(\n\u001B[32m     14\u001B[39m         cloud=\u001B[33m\"\u001B[39m\u001B[33maws\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     15\u001B[39m         region=\u001B[33m\"\u001B[39m\u001B[33mus-east-1\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     16\u001B[39m     )\n\u001B[32m     17\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\pinecone\\control\\pinecone.py:143\u001B[39m, in \u001B[36mPinecone.create_index\u001B[39m\u001B[34m(self, name, spec, dimension, metric, timeout, deletion_protection, vector_type, tags)\u001B[39m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate_index\u001B[39m(\n\u001B[32m    124\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    125\u001B[39m     name: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    132\u001B[39m     tags: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    133\u001B[39m ) -> IndexModel:\n\u001B[32m    134\u001B[39m     req = PineconeDBControlRequestFactory.create_index_request(\n\u001B[32m    135\u001B[39m         name=name,\n\u001B[32m    136\u001B[39m         spec=spec,\n\u001B[32m   (...)\u001B[39m\u001B[32m    141\u001B[39m         tags=tags,\n\u001B[32m    142\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m143\u001B[39m     resp = \u001B[38;5;28mself\u001B[39m.index_api.create_index(create_index_request=req)\n\u001B[32m    145\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m timeout == -\u001B[32m1\u001B[39m:\n\u001B[32m    146\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m IndexModel(resp)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\pinecone\\openapi_support\\endpoint.py:102\u001B[39m, in \u001B[36mEndpoint.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m     92\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"This method is invoked when endpoints are called\u001B[39;00m\n\u001B[32m     93\u001B[39m \u001B[33;03m    Example:\u001B[39;00m\n\u001B[32m     94\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    100\u001B[39m \n\u001B[32m    101\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m102\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.callable(\u001B[38;5;28mself\u001B[39m, *args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\pinecone\\core\\openapi\\db_control\\api\\manage_indexes_api.py:235\u001B[39m, in \u001B[36mManageIndexesApi.__init__.<locals>.__create_index\u001B[39m\u001B[34m(self, create_index_request, **kwargs)\u001B[39m\n\u001B[32m    233\u001B[39m kwargs = \u001B[38;5;28mself\u001B[39m._process_openapi_kwargs(kwargs)\n\u001B[32m    234\u001B[39m kwargs[\u001B[33m\"\u001B[39m\u001B[33mcreate_index_request\u001B[39m\u001B[33m\"\u001B[39m] = create_index_request\n\u001B[32m--> \u001B[39m\u001B[32m235\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.call_with_http_info(**kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\pinecone\\openapi_support\\endpoint.py:134\u001B[39m, in \u001B[36mEndpoint.call_with_http_info\u001B[39m\u001B[34m(self, **kwargs)\u001B[39m\n\u001B[32m    124\u001B[39m params = EndpointUtils.gather_params(\n\u001B[32m    125\u001B[39m     attribute_map=\u001B[38;5;28mself\u001B[39m.attribute_map,\n\u001B[32m    126\u001B[39m     location_map=\u001B[38;5;28mself\u001B[39m.location_map,\n\u001B[32m   (...)\u001B[39m\u001B[32m    129\u001B[39m     kwargs=kwargs,\n\u001B[32m    130\u001B[39m )\n\u001B[32m    132\u001B[39m HeaderUtil.prepare_headers(headers_map=\u001B[38;5;28mself\u001B[39m.headers_map, params=params)\n\u001B[32m--> \u001B[39m\u001B[32m134\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.api_client.call_api(\n\u001B[32m    135\u001B[39m     \u001B[38;5;28mself\u001B[39m.settings[\u001B[33m\"\u001B[39m\u001B[33mendpoint_path\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    136\u001B[39m     \u001B[38;5;28mself\u001B[39m.settings[\u001B[33m\"\u001B[39m\u001B[33mhttp_method\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    137\u001B[39m     path_params=params[\u001B[33m\"\u001B[39m\u001B[33mpath\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    138\u001B[39m     query_params=params[\u001B[33m\"\u001B[39m\u001B[33mquery\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    139\u001B[39m     header_params=params[\u001B[33m\"\u001B[39m\u001B[33mheader\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    140\u001B[39m     body=params[\u001B[33m\"\u001B[39m\u001B[33mbody\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    141\u001B[39m     post_params=params[\u001B[33m\"\u001B[39m\u001B[33mform\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    142\u001B[39m     files=params[\u001B[33m\"\u001B[39m\u001B[33mfile\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    143\u001B[39m     response_type=\u001B[38;5;28mself\u001B[39m.settings[\u001B[33m\"\u001B[39m\u001B[33mresponse_type\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    144\u001B[39m     auth_settings=\u001B[38;5;28mself\u001B[39m.settings[\u001B[33m\"\u001B[39m\u001B[33mauth\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    145\u001B[39m     async_req=kwargs[\u001B[33m\"\u001B[39m\u001B[33masync_req\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    146\u001B[39m     async_threadpool_executor=kwargs.get(\u001B[33m\"\u001B[39m\u001B[33masync_threadpool_executor\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[32m    147\u001B[39m     _check_type=kwargs[\u001B[33m\"\u001B[39m\u001B[33m_check_return_type\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    148\u001B[39m     _return_http_data_only=kwargs[\u001B[33m\"\u001B[39m\u001B[33m_return_http_data_only\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    149\u001B[39m     _preload_content=kwargs[\u001B[33m\"\u001B[39m\u001B[33m_preload_content\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    150\u001B[39m     _request_timeout=kwargs[\u001B[33m\"\u001B[39m\u001B[33m_request_timeout\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    151\u001B[39m     _host=_host,\n\u001B[32m    152\u001B[39m     collection_formats=params[\u001B[33m\"\u001B[39m\u001B[33mcollection_format\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    153\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\pinecone\\openapi_support\\api_client.py:300\u001B[39m, in \u001B[36mApiClient.call_api\u001B[39m\u001B[34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, async_threadpool_executor, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001B[39m\n\u001B[32m    279\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.threadpool_executor.submit(\n\u001B[32m    280\u001B[39m         \u001B[38;5;28mself\u001B[39m.__call_api,\n\u001B[32m    281\u001B[39m         resource_path,\n\u001B[32m   (...)\u001B[39m\u001B[32m    296\u001B[39m         _check_type,\n\u001B[32m    297\u001B[39m     )\n\u001B[32m    299\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m async_req:\n\u001B[32m--> \u001B[39m\u001B[32m300\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.__call_api(\n\u001B[32m    301\u001B[39m         resource_path,\n\u001B[32m    302\u001B[39m         method,\n\u001B[32m    303\u001B[39m         path_params,\n\u001B[32m    304\u001B[39m         query_params,\n\u001B[32m    305\u001B[39m         header_params,\n\u001B[32m    306\u001B[39m         body,\n\u001B[32m    307\u001B[39m         post_params,\n\u001B[32m    308\u001B[39m         files,\n\u001B[32m    309\u001B[39m         response_type,\n\u001B[32m    310\u001B[39m         auth_settings,\n\u001B[32m    311\u001B[39m         _return_http_data_only,\n\u001B[32m    312\u001B[39m         collection_formats,\n\u001B[32m    313\u001B[39m         _preload_content,\n\u001B[32m    314\u001B[39m         _request_timeout,\n\u001B[32m    315\u001B[39m         _host,\n\u001B[32m    316\u001B[39m         _check_type,\n\u001B[32m    317\u001B[39m     )\n\u001B[32m    319\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.pool.apply_async(\n\u001B[32m    320\u001B[39m     \u001B[38;5;28mself\u001B[39m.__call_api,\n\u001B[32m    321\u001B[39m     (\n\u001B[32m   (...)\u001B[39m\u001B[32m    338\u001B[39m     ),\n\u001B[32m    339\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\pinecone\\openapi_support\\api_client.py:178\u001B[39m, in \u001B[36mApiClient.__call_api\u001B[39m\u001B[34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001B[39m\n\u001B[32m    176\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m PineconeApiException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    177\u001B[39m     e.body = e.body.decode(\u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m178\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m    180\u001B[39m \u001B[38;5;28mself\u001B[39m.last_response = response_data\n\u001B[32m    182\u001B[39m return_data = response_data\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\pinecone\\openapi_support\\api_client.py:166\u001B[39m, in \u001B[36mApiClient.__call_api\u001B[39m\u001B[34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001B[39m\n\u001B[32m    157\u001B[39m url = build_request_url(\n\u001B[32m    158\u001B[39m     config=config,\n\u001B[32m    159\u001B[39m     processed_path_params=path_params_tuple,\n\u001B[32m    160\u001B[39m     resource_path=resource_path,\n\u001B[32m    161\u001B[39m     _host=_host,\n\u001B[32m    162\u001B[39m )\n\u001B[32m    164\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    165\u001B[39m     \u001B[38;5;66;03m# perform request and return response\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m166\u001B[39m     response_data = \u001B[38;5;28mself\u001B[39m.request(\n\u001B[32m    167\u001B[39m         method,\n\u001B[32m    168\u001B[39m         url,\n\u001B[32m    169\u001B[39m         query_params=processed_query_params,\n\u001B[32m    170\u001B[39m         headers=headers_tuple,\n\u001B[32m    171\u001B[39m         post_params=processed_post_params,\n\u001B[32m    172\u001B[39m         body=body,\n\u001B[32m    173\u001B[39m         _preload_content=_preload_content,\n\u001B[32m    174\u001B[39m         _request_timeout=_request_timeout,\n\u001B[32m    175\u001B[39m     )\n\u001B[32m    176\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m PineconeApiException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    177\u001B[39m     e.body = e.body.decode(\u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\pinecone\\openapi_support\\api_client.py:380\u001B[39m, in \u001B[36mApiClient.request\u001B[39m\u001B[34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001B[39m\n\u001B[32m    370\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.rest_client.OPTIONS(\n\u001B[32m    371\u001B[39m         url,\n\u001B[32m    372\u001B[39m         query_params=query_params,\n\u001B[32m   (...)\u001B[39m\u001B[32m    377\u001B[39m         body=body,\n\u001B[32m    378\u001B[39m     )\n\u001B[32m    379\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m method == \u001B[33m\"\u001B[39m\u001B[33mPOST\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m380\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.rest_client.POST(\n\u001B[32m    381\u001B[39m         url,\n\u001B[32m    382\u001B[39m         query_params=query_params,\n\u001B[32m    383\u001B[39m         headers=headers,\n\u001B[32m    384\u001B[39m         post_params=post_params,\n\u001B[32m    385\u001B[39m         _preload_content=_preload_content,\n\u001B[32m    386\u001B[39m         _request_timeout=_request_timeout,\n\u001B[32m    387\u001B[39m         body=body,\n\u001B[32m    388\u001B[39m     )\n\u001B[32m    389\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m method == \u001B[33m\"\u001B[39m\u001B[33mPUT\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    390\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.rest_client.PUT(\n\u001B[32m    391\u001B[39m         url,\n\u001B[32m    392\u001B[39m         query_params=query_params,\n\u001B[32m   (...)\u001B[39m\u001B[32m    397\u001B[39m         body=body,\n\u001B[32m    398\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\pinecone\\openapi_support\\rest_utils.py:146\u001B[39m, in \u001B[36mRestClientInterface.POST\u001B[39m\u001B[34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001B[39m\n\u001B[32m    136\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mPOST\u001B[39m(\n\u001B[32m    137\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    138\u001B[39m     url,\n\u001B[32m   (...)\u001B[39m\u001B[32m    144\u001B[39m     _request_timeout=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    145\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m146\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.request(\n\u001B[32m    147\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mPOST\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    148\u001B[39m         url,\n\u001B[32m    149\u001B[39m         headers=headers,\n\u001B[32m    150\u001B[39m         query_params=query_params,\n\u001B[32m    151\u001B[39m         post_params=post_params,\n\u001B[32m    152\u001B[39m         _preload_content=_preload_content,\n\u001B[32m    153\u001B[39m         _request_timeout=_request_timeout,\n\u001B[32m    154\u001B[39m         body=body,\n\u001B[32m    155\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\pinecone\\openapi_support\\rest_urllib3.py:260\u001B[39m, in \u001B[36mUrllib3RestClient.request\u001B[39m\u001B[34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001B[39m\n\u001B[32m    257\u001B[39m     \u001B[38;5;66;03m# log response body\u001B[39;00m\n\u001B[32m    258\u001B[39m     logger.debug(\u001B[33m\"\u001B[39m\u001B[33mresponse body: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m, r.data)\n\u001B[32m--> \u001B[39m\u001B[32m260\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m raise_exceptions_or_return(r)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\pinecone\\openapi_support\\rest_utils.py:49\u001B[39m, in \u001B[36mraise_exceptions_or_return\u001B[39m\u001B[34m(r)\u001B[39m\n\u001B[32m     46\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[32m500\u001B[39m <= r.status <= \u001B[32m599\u001B[39m:\n\u001B[32m     47\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m ServiceException(http_resp=r)\n\u001B[32m---> \u001B[39m\u001B[32m49\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m PineconeApiException(http_resp=r)\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "\u001B[31mPineconeApiException\u001B[39m: (409)\nReason: Conflict\nHTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'x-pinecone-api-version': '2025-01', 'x-cloud-trace-context': '0d1cf92abf7a99e3c5fdf467020d0e4b', 'date': 'Tue, 27 May 2025 18:12:32 GMT', 'server': 'Google Frontend', 'Content-Length': '85', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"error\":{\"code\":\"ALREADY_EXISTS\",\"message\":\"Resource  already exists\"},\"status\":409}\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:16:53.212501Z",
     "start_time": "2025-05-27T18:16:53.207501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_AIP_KEY\n",
    "os.environ[\"OPEN_AI_API_KEY\"] = OPEN_AI_API_KEY"
   ],
   "id": "d564f27a6e6f1bf1",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:12:51.472674Z",
     "start_time": "2025-05-27T18:12:36.848490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,)"
   ],
   "id": "a14dff9d756c7ad",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[28]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m#Embed each chunk and upsert the embeddings into your Pinecone index.\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_pinecone\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PineconeVectorStore\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m docsearch = PineconeVectorStore.from_documents(\n\u001B[32m      5\u001B[39m     documents=text_chunks,\n\u001B[32m      6\u001B[39m     index_name=index_name,\n\u001B[32m      7\u001B[39m     embedding=embeddings,)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:848\u001B[39m, in \u001B[36mVectorStore.from_documents\u001B[39m\u001B[34m(cls, documents, embedding, **kwargs)\u001B[39m\n\u001B[32m    845\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(ids):\n\u001B[32m    846\u001B[39m         kwargs[\u001B[33m\"\u001B[39m\u001B[33mids\u001B[39m\u001B[33m\"\u001B[39m] = ids\n\u001B[32m--> \u001B[39m\u001B[32m848\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_pinecone\\vectorstores.py:823\u001B[39m, in \u001B[36mPineconeVectorStore.from_texts\u001B[39m\u001B[34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, namespace, index_name, upsert_kwargs, pool_threads, embeddings_chunk_size, id_prefix, **kwargs)\u001B[39m\n\u001B[32m    820\u001B[39m pinecone_index = \u001B[38;5;28mcls\u001B[39m.get_pinecone_index(index_name, pool_threads)\n\u001B[32m    821\u001B[39m pinecone = \u001B[38;5;28mcls\u001B[39m(pinecone_index, embedding, text_key, namespace, **kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m823\u001B[39m pinecone.add_texts(\n\u001B[32m    824\u001B[39m     texts,\n\u001B[32m    825\u001B[39m     metadatas=metadatas,\n\u001B[32m    826\u001B[39m     ids=ids,\n\u001B[32m    827\u001B[39m     namespace=namespace,\n\u001B[32m    828\u001B[39m     batch_size=batch_size,\n\u001B[32m    829\u001B[39m     embedding_chunk_size=embeddings_chunk_size,\n\u001B[32m    830\u001B[39m     id_prefix=id_prefix,\n\u001B[32m    831\u001B[39m     **(upsert_kwargs \u001B[38;5;129;01mor\u001B[39;00m {}),\n\u001B[32m    832\u001B[39m )\n\u001B[32m    833\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m pinecone\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_pinecone\\vectorstores.py:312\u001B[39m, in \u001B[36mPineconeVectorStore.add_texts\u001B[39m\u001B[34m(self, texts, metadatas, ids, namespace, batch_size, embedding_chunk_size, id_prefix, **kwargs)\u001B[39m\n\u001B[32m    310\u001B[39m chunk_ids = ids[i : i + embedding_chunk_size]\n\u001B[32m    311\u001B[39m chunk_metadatas = metadatas[i : i + embedding_chunk_size]\n\u001B[32m--> \u001B[39m\u001B[32m312\u001B[39m embeddings = \u001B[38;5;28mself\u001B[39m._embedding.embed_documents(chunk_texts)\n\u001B[32m    313\u001B[39m vector_tuples = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(chunk_ids, embeddings, chunk_metadatas))\n\u001B[32m    314\u001B[39m \u001B[38;5;28mself\u001B[39m.index.upsert(\n\u001B[32m    315\u001B[39m     vectors=vector_tuples,\n\u001B[32m    316\u001B[39m     namespace=namespace,\n\u001B[32m    317\u001B[39m     **kwargs,\n\u001B[32m    318\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:115\u001B[39m, in \u001B[36mHuggingFaceEmbeddings.embed_documents\u001B[39m\u001B[34m(self, texts)\u001B[39m\n\u001B[32m    113\u001B[39m     sentence_transformers.SentenceTransformer.stop_multi_process_pool(pool)\n\u001B[32m    114\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m115\u001B[39m     embeddings = \u001B[38;5;28mself\u001B[39m.client.encode(\n\u001B[32m    116\u001B[39m         texts, show_progress_bar=\u001B[38;5;28mself\u001B[39m.show_progress, **\u001B[38;5;28mself\u001B[39m.encode_kwargs\n\u001B[32m    117\u001B[39m     )\n\u001B[32m    119\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m embeddings.tolist()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:685\u001B[39m, in \u001B[36mSentenceTransformer.encode\u001B[39m\u001B[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001B[39m\n\u001B[32m    682\u001B[39m features.update(extra_features)\n\u001B[32m    684\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m--> \u001B[39m\u001B[32m685\u001B[39m     out_features = \u001B[38;5;28mself\u001B[39m.forward(features, **kwargs)\n\u001B[32m    686\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.device.type == \u001B[33m\"\u001B[39m\u001B[33mhpu\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    687\u001B[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:758\u001B[39m, in \u001B[36mSentenceTransformer.forward\u001B[39m\u001B[34m(self, input, **kwargs)\u001B[39m\n\u001B[32m    756\u001B[39m     module_kwarg_keys = \u001B[38;5;28mself\u001B[39m.module_kwargs.get(module_name, [])\n\u001B[32m    757\u001B[39m     module_kwargs = {key: value \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m kwargs.items() \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m module_kwarg_keys}\n\u001B[32m--> \u001B[39m\u001B[32m758\u001B[39m     \u001B[38;5;28minput\u001B[39m = module(\u001B[38;5;28minput\u001B[39m, **module_kwargs)\n\u001B[32m    759\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:442\u001B[39m, in \u001B[36mTransformer.forward\u001B[39m\u001B[34m(self, features, **kwargs)\u001B[39m\n\u001B[32m    435\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001B[39;00m\n\u001B[32m    436\u001B[39m trans_features = {\n\u001B[32m    437\u001B[39m     key: value\n\u001B[32m    438\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m features.items()\n\u001B[32m    439\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m [\u001B[33m\"\u001B[39m\u001B[33minput_ids\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mattention_mask\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mtoken_type_ids\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33minputs_embeds\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m    440\u001B[39m }\n\u001B[32m--> \u001B[39m\u001B[32m442\u001B[39m outputs = \u001B[38;5;28mself\u001B[39m.auto_model(**trans_features, **kwargs, return_dict=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    443\u001B[39m token_embeddings = outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    444\u001B[39m features[\u001B[33m\"\u001B[39m\u001B[33mtoken_embeddings\u001B[39m\u001B[33m\"\u001B[39m] = token_embeddings\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1016\u001B[39m, in \u001B[36mBertModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m   1009\u001B[39m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[32m   1010\u001B[39m \u001B[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001B[39;00m\n\u001B[32m   1011\u001B[39m \u001B[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001B[39;00m\n\u001B[32m   1012\u001B[39m \u001B[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001B[39;00m\n\u001B[32m   1013\u001B[39m \u001B[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001B[39;00m\n\u001B[32m   1014\u001B[39m head_mask = \u001B[38;5;28mself\u001B[39m.get_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m.config.num_hidden_layers)\n\u001B[32m-> \u001B[39m\u001B[32m1016\u001B[39m encoder_outputs = \u001B[38;5;28mself\u001B[39m.encoder(\n\u001B[32m   1017\u001B[39m     embedding_output,\n\u001B[32m   1018\u001B[39m     attention_mask=extended_attention_mask,\n\u001B[32m   1019\u001B[39m     head_mask=head_mask,\n\u001B[32m   1020\u001B[39m     encoder_hidden_states=encoder_hidden_states,\n\u001B[32m   1021\u001B[39m     encoder_attention_mask=encoder_extended_attention_mask,\n\u001B[32m   1022\u001B[39m     past_key_values=past_key_values,\n\u001B[32m   1023\u001B[39m     use_cache=use_cache,\n\u001B[32m   1024\u001B[39m     output_attentions=output_attentions,\n\u001B[32m   1025\u001B[39m     output_hidden_states=output_hidden_states,\n\u001B[32m   1026\u001B[39m     return_dict=return_dict,\n\u001B[32m   1027\u001B[39m )\n\u001B[32m   1028\u001B[39m sequence_output = encoder_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m   1029\u001B[39m pooled_output = \u001B[38;5;28mself\u001B[39m.pooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.pooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:662\u001B[39m, in \u001B[36mBertEncoder.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m    651\u001B[39m     layer_outputs = \u001B[38;5;28mself\u001B[39m._gradient_checkpointing_func(\n\u001B[32m    652\u001B[39m         layer_module.\u001B[34m__call__\u001B[39m,\n\u001B[32m    653\u001B[39m         hidden_states,\n\u001B[32m   (...)\u001B[39m\u001B[32m    659\u001B[39m         output_attentions,\n\u001B[32m    660\u001B[39m     )\n\u001B[32m    661\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m662\u001B[39m     layer_outputs = layer_module(\n\u001B[32m    663\u001B[39m         hidden_states,\n\u001B[32m    664\u001B[39m         attention_mask,\n\u001B[32m    665\u001B[39m         layer_head_mask,\n\u001B[32m    666\u001B[39m         encoder_hidden_states,\n\u001B[32m    667\u001B[39m         encoder_attention_mask,\n\u001B[32m    668\u001B[39m         past_key_value,\n\u001B[32m    669\u001B[39m         output_attentions,\n\u001B[32m    670\u001B[39m     )\n\u001B[32m    672\u001B[39m hidden_states = layer_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    673\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:552\u001B[39m, in \u001B[36mBertLayer.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[39m\n\u001B[32m    540\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\n\u001B[32m    541\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    542\u001B[39m     hidden_states: torch.Tensor,\n\u001B[32m   (...)\u001B[39m\u001B[32m    549\u001B[39m ) -> Tuple[torch.Tensor]:\n\u001B[32m    550\u001B[39m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[32m    551\u001B[39m     self_attn_past_key_value = past_key_value[:\u001B[32m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m552\u001B[39m     self_attention_outputs = \u001B[38;5;28mself\u001B[39m.attention(\n\u001B[32m    553\u001B[39m         hidden_states,\n\u001B[32m    554\u001B[39m         attention_mask,\n\u001B[32m    555\u001B[39m         head_mask,\n\u001B[32m    556\u001B[39m         output_attentions=output_attentions,\n\u001B[32m    557\u001B[39m         past_key_value=self_attn_past_key_value,\n\u001B[32m    558\u001B[39m     )\n\u001B[32m    559\u001B[39m     attention_output = self_attention_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    561\u001B[39m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:482\u001B[39m, in \u001B[36mBertAttention.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[39m\n\u001B[32m    472\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\n\u001B[32m    473\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    474\u001B[39m     hidden_states: torch.Tensor,\n\u001B[32m   (...)\u001B[39m\u001B[32m    480\u001B[39m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    481\u001B[39m ) -> Tuple[torch.Tensor]:\n\u001B[32m--> \u001B[39m\u001B[32m482\u001B[39m     self_outputs = \u001B[38;5;28mself\u001B[39m.self(\n\u001B[32m    483\u001B[39m         hidden_states,\n\u001B[32m    484\u001B[39m         attention_mask,\n\u001B[32m    485\u001B[39m         head_mask,\n\u001B[32m    486\u001B[39m         encoder_hidden_states,\n\u001B[32m    487\u001B[39m         encoder_attention_mask,\n\u001B[32m    488\u001B[39m         past_key_value,\n\u001B[32m    489\u001B[39m         output_attentions,\n\u001B[32m    490\u001B[39m     )\n\u001B[32m    491\u001B[39m     attention_output = \u001B[38;5;28mself\u001B[39m.output(self_outputs[\u001B[32m0\u001B[39m], hidden_states)\n\u001B[32m    492\u001B[39m     outputs = (attention_output,) + self_outputs[\u001B[32m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:375\u001B[39m, in \u001B[36mBertSdpaSelfAttention.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[39m\n\u001B[32m    373\u001B[39m     key_layer, value_layer = past_key_value\n\u001B[32m    374\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m375\u001B[39m     key_layer = \u001B[38;5;28mself\u001B[39m.transpose_for_scores(\u001B[38;5;28mself\u001B[39m.key(current_states))\n\u001B[32m    376\u001B[39m     value_layer = \u001B[38;5;28mself\u001B[39m.transpose_for_scores(\u001B[38;5;28mself\u001B[39m.value(current_states))\n\u001B[32m    377\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_cross_attention:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.linear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m.weight, \u001B[38;5;28mself\u001B[39m.bias)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:13:10.098542Z",
     "start_time": "2025-05-27T18:13:08.703974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Load Existing INdex\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ],
   "id": "dcb88063e30f684e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:13:14.053228Z",
     "start_time": "2025-05-27T18:13:14.040238Z"
    }
   },
   "cell_type": "code",
   "source": "docsearch",
   "id": "cd47dddb1d4a627c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x250bc5d73b0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:13:18.791847Z",
     "start_time": "2025-05-27T18:13:18.781075Z"
    }
   },
   "cell_type": "code",
   "source": "retriever = docsearch.as_retriever(search_type=\"similarity\",search_kwargs={\"k\": 3})",
   "id": "fc32edca799792b8",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:13:21.871269Z",
     "start_time": "2025-05-27T18:13:20.346873Z"
    }
   },
   "cell_type": "code",
   "source": "retrieved_docs = retriever.invoke(\"What is Acne?\")",
   "id": "dd16eed6cc580fb",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:13:23.386098Z",
     "start_time": "2025-05-27T18:13:23.380382Z"
    }
   },
   "cell_type": "code",
   "source": "retrieved_docs",
   "id": "71338ff492348585",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='31de3b7d-8dd6-4a63-8f40-a475ed1e09ef', metadata={'page': 3353.0, 'source': 'Data\\\\Encyclopedia-of-Medicine.pdf'}, page_content='Acne A chronic inflammation of the sebaceous\\nglands that manifests as blackheads, whiteheads,and/or pustules on the face or trunk.\\nPsoriasis A skin disorder of chronic, itchy scaling\\nmost commonly at sites of repeated minor trauma(e.g. elbows, knees, and skin folds). It affects up to2% of the population in Western countriesmalesand females equally.\\nRosacea A chronic inflammation of the face, with'),\n",
       " Document(id='1b97b4af-5c6a-4c88-ad65-a6bc8a7211e4', metadata={'page': 54.0, 'source': 'Data\\\\Encyclopedia-of-Medicine.pdf'}, page_content='(male hormones) cause the glands to produce toomuch sebum. When excess sebum combines withdead, sticky skin cells, a hard plug, or comedo, formsthat blocks the pore. Mild noninflammatory acne con-sists of the two types of comedones, whiteheads andblackheads.\\nModerate and severe inflammatory types of acne\\nresult after the plugged follicle is invaded byPropionibacterium acnes , a bacteria that normally\\nlives on the skin. A pimple forms when the damaged'),\n",
       " Document(id='6f46ec9c-dbe2-4391-82eb-ba35405ee93c', metadata={'page': 269.0, 'source': 'Data\\\\Encyclopedia-of-Medicine.pdf'}, page_content='different purposes. For example, lotions, soaps, gels,and creams containing benzoyl peroxide or tretinoin\\nmay be used to clear up mild to moderately severe\\nacne. Isotretinoin (Accutane) is prescribed only forvery severe, disfiguring acne.\\nAcne is a skin condition that occurs when pores or\\nhair follicles become blocked. This blockage allows a\\nwaxy material called sebum to collect inside the poresor follicles. Normally, sebum flows out onto the skin\\n240 GALE ENCYCLOPEDIA OF MEDICINEAntiacne drugs')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:18:12.621719Z",
     "start_time": "2025-05-27T18:18:11.480640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.4, max_tokens=500,api_key=OPEN_AI_API_KEY)\n"
   ],
   "id": "ef33cfd97c6d1fcf",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:28:06.089266Z",
     "start_time": "2025-05-27T18:28:05.875180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are assisting for question-answering task. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you don't know.\"\n",
    "    \"Use three sentences maximum and keep the answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "\n",
    "     ]\n",
    ")"
   ],
   "id": "2a78aa37bd0347d",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:29:50.736335Z",
     "start_time": "2025-05-27T18:29:50.723337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ],
   "id": "38fb3b4c3cd8f24",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T18:31:37.145065Z",
     "start_time": "2025-05-27T18:31:22.755982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = rag_chain.invoke({\"input\":\"What is Acne?\"})\n",
    "print(response[\"answer\"])\n"
   ],
   "id": "16b9460b5b73d9f1",
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRateLimitError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[41]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m response = rag_chain.invoke({\u001B[33m\"\u001B[39m\u001B[33minput\u001B[39m\u001B[33m\"\u001B[39m:\u001B[33m\"\u001B[39m\u001B[33mWhat is Acne?\u001B[39m\u001B[33m\"\u001B[39m})\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(response[\u001B[33m\"\u001B[39m\u001B[33manswer\u001B[39m\u001B[33m\"\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5430\u001B[39m, in \u001B[36minvoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   5422\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   5423\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mainvoke\u001B[39m(\n\u001B[32m   5424\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   5427\u001B[39m     **kwargs: Optional[Any],\n\u001B[32m   5428\u001B[39m ) -> Output:\n\u001B[32m   5429\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.bound.ainvoke(\n\u001B[32m-> \u001B[39m\u001B[32m5430\u001B[39m         \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   5431\u001B[39m         \u001B[38;5;28mself\u001B[39m._merge_configs(config),\n\u001B[32m   5432\u001B[39m         **{**\u001B[38;5;28mself\u001B[39m.kwargs, **kwargs},\n\u001B[32m   5433\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001B[39m, in \u001B[36minvoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   3040\u001B[39m         run_manager.on_chain_end(\u001B[38;5;28minput\u001B[39m)\n\u001B[32m   3041\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m cast(\u001B[33m\"\u001B[39m\u001B[33mOutput\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28minput\u001B[39m)\n\u001B[32m   3043\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   3044\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mainvoke\u001B[39m(\n\u001B[32m   3045\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   3046\u001B[39m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[32m-> \u001B[39m\u001B[32m3047\u001B[39m     config: Optional[RunnableConfig] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   3048\u001B[39m     **kwargs: Optional[Any],\n\u001B[32m   3049\u001B[39m ) -> Output:\n\u001B[32m   3050\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbeta\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mrunnables\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcontext\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m aconfig_with_context\n\u001B[32m   3052\u001B[39m     \u001B[38;5;66;03m# setup callbacks and context\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:511\u001B[39m, in \u001B[36mRunnableAssign.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    504\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    505\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m    506\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    509\u001B[39m     **kwargs: Any,\n\u001B[32m    510\u001B[39m ) -> \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[32m--> \u001B[39m\u001B[32m511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_with_config(\u001B[38;5;28mself\u001B[39m._invoke, \u001B[38;5;28minput\u001B[39m, config, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1940\u001B[39m, in \u001B[36m_call_with_config\u001B[39m\u001B[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001B[39m\n\u001B[32m   1928\u001B[39m         output = cast(\n\u001B[32m   1929\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mOutput\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   1930\u001B[39m             context.run(\n\u001B[32m   (...)\u001B[39m\u001B[32m   1937\u001B[39m             ),\n\u001B[32m   1938\u001B[39m         )\n\u001B[32m   1939\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m-> \u001B[39m\u001B[32m1940\u001B[39m     run_manager.on_chain_error(e)\n\u001B[32m   1941\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[32m   1942\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001B[39m, in \u001B[36mcall_func_with_variable_args\u001B[39m\u001B[34m(func, input, config, run_manager, **kwargs)\u001B[39m\n\u001B[32m    426\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[32m    427\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m] = run_manager\n\u001B[32m--> \u001B[39m\u001B[32m428\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28minput\u001B[39m, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:497\u001B[39m, in \u001B[36mRunnableAssign._invoke\u001B[39m\u001B[34m(self, input, run_manager, config, **kwargs)\u001B[39m\n\u001B[32m    492\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mThe input to RunnablePassthrough.assign() must be a dict.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    493\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)  \u001B[38;5;66;03m# noqa: TRY004\u001B[39;00m\n\u001B[32m    495\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m    496\u001B[39m     **\u001B[38;5;28minput\u001B[39m,\n\u001B[32m--> \u001B[39m\u001B[32m497\u001B[39m     **\u001B[38;5;28mself\u001B[39m.mapper.invoke(\n\u001B[32m    498\u001B[39m         \u001B[38;5;28minput\u001B[39m,\n\u001B[32m    499\u001B[39m         patch_config(config, callbacks=run_manager.get_child()),\n\u001B[32m    500\u001B[39m         **kwargs,\n\u001B[32m    501\u001B[39m     ),\n\u001B[32m    502\u001B[39m }\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3774\u001B[39m, in \u001B[36minvoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   3766\u001B[39m         run_manager.on_chain_end(output)\n\u001B[32m   3767\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m output\n\u001B[32m   3769\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   3770\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mainvoke\u001B[39m(\n\u001B[32m   3771\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   3772\u001B[39m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[32m   3773\u001B[39m     config: Optional[RunnableConfig] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m-> \u001B[39m\u001B[32m3774\u001B[39m     **kwargs: Optional[Any],\n\u001B[32m   3775\u001B[39m ) -> \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[32m   3776\u001B[39m     \u001B[38;5;66;03m# setup callbacks\u001B[39;00m\n\u001B[32m   3777\u001B[39m     config = ensure_config(config)\n\u001B[32m   3778\u001B[39m     callback_manager = get_async_callback_manager_for_config(config)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\concurrent\\futures\\_base.py:456\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    454\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[32m    455\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state == FINISHED:\n\u001B[32m--> \u001B[39m\u001B[32m456\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.__get_result()\n\u001B[32m    457\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    458\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\concurrent\\futures\\_base.py:401\u001B[39m, in \u001B[36mFuture.__get_result\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    399\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception:\n\u001B[32m    400\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m401\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception\n\u001B[32m    402\u001B[39m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    403\u001B[39m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[32m    404\u001B[39m         \u001B[38;5;28mself\u001B[39m = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\concurrent\\futures\\thread.py:59\u001B[39m, in \u001B[36m_WorkItem.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     56\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     result = \u001B[38;5;28mself\u001B[39m.fn(*\u001B[38;5;28mself\u001B[39m.args, **\u001B[38;5;28mself\u001B[39m.kwargs)\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m     61\u001B[39m     \u001B[38;5;28mself\u001B[39m.future.set_exception(exc)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3758\u001B[39m, in \u001B[36m_invoke_step\u001B[39m\u001B[34m(step, input_, config, key)\u001B[39m\n\u001B[32m   3753\u001B[39m     steps = \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28mself\u001B[39m.steps__)\n\u001B[32m   3755\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m get_executor_for_config(config) \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[32m   3756\u001B[39m         futures = [\n\u001B[32m   3757\u001B[39m             executor.submit(_invoke_step, step, \u001B[38;5;28minput\u001B[39m, config, key)\n\u001B[32m-> \u001B[39m\u001B[32m3758\u001B[39m             \u001B[38;5;28;01mfor\u001B[39;00m key, step \u001B[38;5;129;01min\u001B[39;00m steps.items()\n\u001B[32m   3759\u001B[39m         ]\n\u001B[32m   3760\u001B[39m         output = {key: future.result() \u001B[38;5;28;01mfor\u001B[39;00m key, future \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(steps, futures)}\n\u001B[32m   3761\u001B[39m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5430\u001B[39m, in \u001B[36minvoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   5422\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   5423\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mainvoke\u001B[39m(\n\u001B[32m   5424\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   5427\u001B[39m     **kwargs: Optional[Any],\n\u001B[32m   5428\u001B[39m ) -> Output:\n\u001B[32m   5429\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.bound.ainvoke(\n\u001B[32m-> \u001B[39m\u001B[32m5430\u001B[39m         \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   5431\u001B[39m         \u001B[38;5;28mself\u001B[39m._merge_configs(config),\n\u001B[32m   5432\u001B[39m         **{**\u001B[38;5;28mself\u001B[39m.kwargs, **kwargs},\n\u001B[32m   5433\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001B[39m, in \u001B[36minvoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   3040\u001B[39m         run_manager.on_chain_end(\u001B[38;5;28minput\u001B[39m)\n\u001B[32m   3041\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m cast(\u001B[33m\"\u001B[39m\u001B[33mOutput\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28minput\u001B[39m)\n\u001B[32m   3043\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   3044\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mainvoke\u001B[39m(\n\u001B[32m   3045\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   3046\u001B[39m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[32m-> \u001B[39m\u001B[32m3047\u001B[39m     config: Optional[RunnableConfig] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   3048\u001B[39m     **kwargs: Optional[Any],\n\u001B[32m   3049\u001B[39m ) -> Output:\n\u001B[32m   3050\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbeta\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mrunnables\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcontext\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m aconfig_with_context\n\u001B[32m   3052\u001B[39m     \u001B[38;5;66;03m# setup callbacks and context\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:387\u001B[39m, in \u001B[36mBaseLLM.invoke\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    376\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    377\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m    378\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    383\u001B[39m     **kwargs: Any,\n\u001B[32m    384\u001B[39m ) -> \u001B[38;5;28mstr\u001B[39m:\n\u001B[32m    385\u001B[39m     config = ensure_config(config)\n\u001B[32m    386\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[32m--> \u001B[39m\u001B[32m387\u001B[39m         \u001B[38;5;28mself\u001B[39m.generate_prompt(\n\u001B[32m    388\u001B[39m             [\u001B[38;5;28mself\u001B[39m._convert_input(\u001B[38;5;28minput\u001B[39m)],\n\u001B[32m    389\u001B[39m             stop=stop,\n\u001B[32m    390\u001B[39m             callbacks=config.get(\u001B[33m\"\u001B[39m\u001B[33mcallbacks\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m    391\u001B[39m             tags=config.get(\u001B[33m\"\u001B[39m\u001B[33mtags\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m    392\u001B[39m             metadata=config.get(\u001B[33m\"\u001B[39m\u001B[33mmetadata\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m    393\u001B[39m             run_name=config.get(\u001B[33m\"\u001B[39m\u001B[33mrun_name\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m    394\u001B[39m             run_id=config.pop(\u001B[33m\"\u001B[39m\u001B[33mrun_id\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[32m    395\u001B[39m             **kwargs,\n\u001B[32m    396\u001B[39m         )\n\u001B[32m    397\u001B[39m         .generations[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m]\n\u001B[32m    398\u001B[39m         .text\n\u001B[32m    399\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:764\u001B[39m, in \u001B[36mBaseLLM.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m    755\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    756\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_prompt\u001B[39m(\n\u001B[32m    757\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    761\u001B[39m     **kwargs: Any,\n\u001B[32m    762\u001B[39m ) -> LLMResult:\n\u001B[32m    763\u001B[39m     prompt_strings = [p.to_string() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m--> \u001B[39m\u001B[32m764\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:971\u001B[39m, in \u001B[36mBaseLLM.generate\u001B[39m\u001B[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    956\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m.cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m get_llm_cache() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[32m    957\u001B[39m     run_managers = [\n\u001B[32m    958\u001B[39m         callback_manager.on_llm_start(\n\u001B[32m    959\u001B[39m             \u001B[38;5;28mself\u001B[39m._serialized,\n\u001B[32m   (...)\u001B[39m\u001B[32m    969\u001B[39m         )\n\u001B[32m    970\u001B[39m     ]\n\u001B[32m--> \u001B[39m\u001B[32m971\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._generate_helper(\n\u001B[32m    972\u001B[39m         prompts,\n\u001B[32m    973\u001B[39m         stop,\n\u001B[32m    974\u001B[39m         run_managers,\n\u001B[32m    975\u001B[39m         new_arg_supported=\u001B[38;5;28mbool\u001B[39m(new_arg_supported),\n\u001B[32m    976\u001B[39m         **kwargs,\n\u001B[32m    977\u001B[39m     )\n\u001B[32m    978\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(missing_prompts) > \u001B[32m0\u001B[39m:\n\u001B[32m    979\u001B[39m     run_managers = [\n\u001B[32m    980\u001B[39m         callback_managers[idx].on_llm_start(\n\u001B[32m    981\u001B[39m             \u001B[38;5;28mself\u001B[39m._serialized,\n\u001B[32m   (...)\u001B[39m\u001B[32m    988\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m missing_prompt_idxs\n\u001B[32m    989\u001B[39m     ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:790\u001B[39m, in \u001B[36mBaseLLM._generate_helper\u001B[39m\u001B[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001B[39m\n\u001B[32m    779\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_generate_helper\u001B[39m(\n\u001B[32m    780\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    781\u001B[39m     prompts: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m],\n\u001B[32m   (...)\u001B[39m\u001B[32m    786\u001B[39m     **kwargs: Any,\n\u001B[32m    787\u001B[39m ) -> LLMResult:\n\u001B[32m    788\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    789\u001B[39m         output = (\n\u001B[32m--> \u001B[39m\u001B[32m790\u001B[39m             \u001B[38;5;28mself\u001B[39m._generate(\n\u001B[32m    791\u001B[39m                 prompts,\n\u001B[32m    792\u001B[39m                 stop=stop,\n\u001B[32m    793\u001B[39m                 \u001B[38;5;66;03m# TODO: support multiple run managers\u001B[39;00m\n\u001B[32m    794\u001B[39m                 run_manager=run_managers[\u001B[32m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m run_managers \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    795\u001B[39m                 **kwargs,\n\u001B[32m    796\u001B[39m             )\n\u001B[32m    797\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[32m    798\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._generate(prompts, stop=stop)\n\u001B[32m    799\u001B[39m         )\n\u001B[32m    800\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    801\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m run_manager \u001B[38;5;129;01min\u001B[39;00m run_managers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\langchain_openai\\llms\\base.py:330\u001B[39m, in \u001B[36mBaseOpenAI._generate\u001B[39m\u001B[34m(self, prompts, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m    314\u001B[39m     choices.append(\n\u001B[32m    315\u001B[39m         {\n\u001B[32m    316\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mtext\u001B[39m\u001B[33m\"\u001B[39m: generation.text,\n\u001B[32m   (...)\u001B[39m\u001B[32m    327\u001B[39m         }\n\u001B[32m    328\u001B[39m     )\n\u001B[32m    329\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m330\u001B[39m     response = \u001B[38;5;28mself\u001B[39m.client.create(prompt=_prompts, **params)\n\u001B[32m    331\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, \u001B[38;5;28mdict\u001B[39m):\n\u001B[32m    332\u001B[39m         \u001B[38;5;66;03m# V1 client returns the response in an PyDantic object instead of\u001B[39;00m\n\u001B[32m    333\u001B[39m         \u001B[38;5;66;03m# dict. For the transition period, we deep convert it to dict.\u001B[39;00m\n\u001B[32m    334\u001B[39m         response = response.model_dump()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001B[39m, in \u001B[36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    285\u001B[39m             msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[32m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    286\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[32m--> \u001B[39m\u001B[32m287\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m func(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\openai\\resources\\completions.py:541\u001B[39m, in \u001B[36mCompletions.create\u001B[39m\u001B[34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m    512\u001B[39m \u001B[38;5;129m@required_args\u001B[39m([\u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mprompt\u001B[39m\u001B[33m\"\u001B[39m], [\u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mprompt\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m    513\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m    514\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    539\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = NOT_GIVEN,\n\u001B[32m    540\u001B[39m ) -> Completion | Stream[Completion]:\n\u001B[32m--> \u001B[39m\u001B[32m541\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._post(\n\u001B[32m    542\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m/completions\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    543\u001B[39m         body=maybe_transform(\n\u001B[32m    544\u001B[39m             {\n\u001B[32m    545\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m: model,\n\u001B[32m    546\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mprompt\u001B[39m\u001B[33m\"\u001B[39m: prompt,\n\u001B[32m    547\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mbest_of\u001B[39m\u001B[33m\"\u001B[39m: best_of,\n\u001B[32m    548\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mecho\u001B[39m\u001B[33m\"\u001B[39m: echo,\n\u001B[32m    549\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mfrequency_penalty\u001B[39m\u001B[33m\"\u001B[39m: frequency_penalty,\n\u001B[32m    550\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mlogit_bias\u001B[39m\u001B[33m\"\u001B[39m: logit_bias,\n\u001B[32m    551\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mlogprobs\u001B[39m\u001B[33m\"\u001B[39m: logprobs,\n\u001B[32m    552\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmax_tokens\u001B[39m\u001B[33m\"\u001B[39m: max_tokens,\n\u001B[32m    553\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mn\u001B[39m\u001B[33m\"\u001B[39m: n,\n\u001B[32m    554\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mpresence_penalty\u001B[39m\u001B[33m\"\u001B[39m: presence_penalty,\n\u001B[32m    555\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mseed\u001B[39m\u001B[33m\"\u001B[39m: seed,\n\u001B[32m    556\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstop\u001B[39m\u001B[33m\"\u001B[39m: stop,\n\u001B[32m    557\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m: stream,\n\u001B[32m    558\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstream_options\u001B[39m\u001B[33m\"\u001B[39m: stream_options,\n\u001B[32m    559\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33msuffix\u001B[39m\u001B[33m\"\u001B[39m: suffix,\n\u001B[32m    560\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtemperature\u001B[39m\u001B[33m\"\u001B[39m: temperature,\n\u001B[32m    561\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtop_p\u001B[39m\u001B[33m\"\u001B[39m: top_p,\n\u001B[32m    562\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m: user,\n\u001B[32m    563\u001B[39m             },\n\u001B[32m    564\u001B[39m             completion_create_params.CompletionCreateParamsStreaming\n\u001B[32m    565\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m stream\n\u001B[32m    566\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001B[32m    567\u001B[39m         ),\n\u001B[32m    568\u001B[39m         options=make_request_options(\n\u001B[32m    569\u001B[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001B[32m    570\u001B[39m         ),\n\u001B[32m    571\u001B[39m         cast_to=Completion,\n\u001B[32m    572\u001B[39m         stream=stream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    573\u001B[39m         stream_cls=Stream[Completion],\n\u001B[32m    574\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\openai\\_base_client.py:1239\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1225\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1226\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1227\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1234\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1235\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1236\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1237\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1238\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1239\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28mself\u001B[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\MediAI\\Lib\\site-packages\\openai\\_base_client.py:1034\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1031\u001B[39m             err.response.read()\n\u001B[32m   1033\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1034\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1036\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1038\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mRateLimitError\u001B[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
